{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1cc2b6",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов. (Шеин Александр)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9df3ca",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "853dc891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from razdel import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "def use_vectorizer(vectorizer, train, test):\n",
    "    X_train = vectorizer.fit_transform(train.comment)\n",
    "    X_test = vectorizer.transform(test.comment)\n",
    "    y_train = train.toxic.values\n",
    "    y_test = test.toxic.values\n",
    "    classifier = MultinomialNB(fit_prior=False)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "\n",
    "def run_experiment():\n",
    "    data = pd.read_csv('labeled.csv')\n",
    "    train, test = train_test_split(data, test_size=0.1)\n",
    "    train.reset_index(inplace=True)\n",
    "    test.reset_index(inplace=True)\n",
    "    default_vectorizer = TfidfVectorizer(min_df=5, max_df=0.6)\n",
    "    custom_vectorizer = TfidfVectorizer(min_df=5, max_df=0.6,\n",
    "                                        tokenizer=lambda stream: [token.text for token in tokenize(stream) if\n",
    "                                                                  token.text not in punctuation])\n",
    "    print('Results with default tokenizer:\\n')\n",
    "    use_vectorizer(default_vectorizer, train, test)\n",
    "    print('Results with razdel tokenizer:\\n')\n",
    "    use_vectorizer(custom_vectorizer, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2232ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with default tokenizer:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.90       969\n",
      "         1.0       0.80      0.77      0.78       473\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.84      0.84      0.84      1442\n",
      "weighted avg       0.86      0.86      0.86      1442\n",
      "\n",
      "Results with razdel tokenizer:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.91      0.90       969\n",
      "         1.0       0.80      0.77      0.78       473\n",
      "\n",
      "    accuracy                           0.86      1442\n",
      "   macro avg       0.84      0.84      0.84      1442\n",
      "weighted avg       0.86      0.86      0.86      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49c2c2",
   "metadata": {},
   "source": [
    "Хотя в этом случае результаты показывают незначительное преимущество у токенайзера razdel (по показателю полноты), можно сказать, что разницы практически нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86feabed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with default tokenizer:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.89       946\n",
      "         1.0       0.80      0.75      0.78       496\n",
      "\n",
      "    accuracy                           0.85      1442\n",
      "   macro avg       0.84      0.83      0.83      1442\n",
      "weighted avg       0.85      0.85      0.85      1442\n",
      "\n",
      "Results with razdel tokenizer:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.90      0.89       946\n",
      "         1.0       0.80      0.74      0.77       496\n",
      "\n",
      "    accuracy                           0.85      1442\n",
      "   macro avg       0.84      0.82      0.83      1442\n",
      "weighted avg       0.85      0.85      0.85      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee424b68",
   "metadata": {},
   "source": [
    "В этом эксперименте данные разбились на обучающую и тестовую выборку по-другому, и данные показали преимущество уже у дефолтного токенайзера. Изменения опять же незначительны. Можно сделать вывод, что токенайзер не особо влияет на эффективность модели, гораздо большее значение имеет правильный выбор самой модели. Ну это очевидно. В дефолтном токенайзере используется регулярное выражение \"(?u)\\b\\w\\w+\\b\", и в подавляющем большинстве случаев этого достаточно. Этот токенайзер отработает некорректно, например на словах,в которых есть дефис или апостроф. Даже если считать, что razdel обработает их корректно, такие незначительные случаи вряд ли могут повлиять на итоговый результат. И вообще неизвестно, что лучше: разбивать такие слова на два или оставлять как одно. Всё зависит от решаемой задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebc968b",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11efeb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Document         я       ты         и    только        не        он\n",
      "0            я и ты  0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
      "1            ты и я  0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
      "2  я, я, и только я  0.133886  0.00000  0.102165  0.183258  0.000000  0.000000\n",
      "3       только не я  0.074381  0.00000  0.000000  0.305430  0.536479  0.000000\n",
      "4                он  0.000000  0.00000  0.000000  0.000000  0.000000  1.609438\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import log\n",
    "import re\n",
    "\n",
    "# инициализируем DataFrame значениями из исходной таблицы, добавляя заголовок первого столбца \"Document\"\n",
    "data = pd.DataFrame([['я и ты', 1, 1, 1, 0, 0, 0],\n",
    "                     ['ты и я', 1, 1, 1, 0, 0, 0],\n",
    "                     ['я, я, и только я', 3, 0, 1, 1, 0, 0],\n",
    "                     ['только не я', 1, 0, 0, 1, 1, 0],\n",
    "                     ['он', 0, 0, 0, 0, 0, 1]],\n",
    "                    columns=['Document', 'я', 'ты', 'и', 'только', 'не', 'он'])\n",
    "words = [header for header in data.columns if header != 'Document']  # слова - это все заголовки, кроме \"Document\"\n",
    "n = len(data['Document'])  # N Из формулы - общее число документов\n",
    "dfs = {}  # сюда запишем количества документов, в которых встречается то или иное слово\n",
    "for word in words:\n",
    "    data[word] = data[word].astype('float')  # результат будем писать в ту же таблицу, поэтому приводим её к float\n",
    "    dfs[word] = sum(1 for document in data['Document'] if word in document)  # подсчёт df слова\n",
    "for ind, row in data.iterrows():  # проходим по документам\n",
    "    doc_len = len(re.findall(r'\\w+', row['Document']))  # определяем число слов в документе\n",
    "    for word in words:  # проходим по словам в документе\n",
    "        tf = row[word] / doc_len  # считаем tf из формулы. Число вхождений слова в документ уже есть в таблице.\n",
    "        # Осталось разделить её на число слов в документе\n",
    "        data.at[ind, word] = tf * log(n / dfs[word])  # применяем формулу\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf7069",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4a34d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for classifier \"MultinomialNB\" with \"CountVectorizer\" is 0.781316348195329\n",
      "The most toxic comments for this classifier are:\n",
      "\n",
      "TOXIC: : Пиздец сука залётная зверушка даже тут насрать успела. Мало того что правил не знает так ещё и права...\n",
      "NON-TOXIC: Может вас просто собаки бесят?) меня не собаки бесят, а проявление агрессии.. Давить собак - проявля...\n",
      "TOXIC: : Не зря, вас, хохлов, свиньями кличут. Вы и есть грязные животные, не способные к любви, привязанност...\n",
      "TOXIC: : Ты либо не знаешь правил русского языка либо шизофреник. Нет - предикатив, отрицающий факт существов...\n",
      "TOXIC: : В России два пола. Гомосеком быть стыдно и опасно. Негры - это негры, а не афроктототам. Женщины име...\n",
      "TOXIC: : ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ ...\n",
      "NON-TOXIC: Раз уж вакханалия продолжается, давайте в этом треде продолжать собирать ворох банов. Копирую из про...\n",
      "NON-TOXIC: та ну, хуйня это все про джентельменство . меня в свое время эти брачные игрища так сильно заебали, ...\n",
      "TOXIC: : В очередной раз убеждаюсь, что двачеры редкостные говноеды и хуесосы. Ладно там гоблин скурвился, ва...\n",
      "TOXIC: : По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засран...\n",
      "\n",
      "F1 score for classifier \"LogisticRegression\" with \"TfidfVectorizer\" is 0.7815126050420168\n",
      "The most toxic comments for this classifier are:\n",
      "\n",
      "TOXIC: : ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ ...\n",
      "TOXIC: : Нахуй ты высрался тогда тут? МНЕ НИНРАВИЦА ЯСКОЗАЛ ХРЯ...\n",
      "TOXIC: : Какие же хохлы всадники, пиздец просто....\n",
      "TOXIC: : Блять, маргиналошизики, чего вас так тянет сюда? Пиздуйте в свой тред и там создавайте борду с ue b ...\n",
      "TOXIC: : По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засран...\n",
      "TOXIC: : Блять какой же жырный сука старый! Сороковник ему небось......\n",
      "TOXIC: : И оставить бумажку: хуй тебе в рот и твоей мамашке...\n",
      "TOXIC: : блядь, заткнись ты . я уже взлетаю нахуй....\n",
      "TOXIC: : Блядь, хохлы, вы бы хоть с проксей писали, няши тупые....\n",
      "TOXIC: : Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло...\n",
      "\n",
      "F1 score for classifier \"MultinomialNB\" with \"TfidfVectorizer\" is 0.7819383259911894\n",
      "The most toxic comments for this classifier are:\n",
      "\n",
      "TOXIC: : Пидорашка у своего носа хуя не замечает, кек лол....\n",
      "TOXIC: : враги Путина клоун блядь, какой он враг Пыни??? Сисян политический противник Пыни, у них порно-полит...\n",
      "TOXIC: : Блять какой же жырный сука старый! Сороковник ему небось......\n",
      "TOXIC: : ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ ...\n",
      "TOXIC: : В очередной раз убеждаюсь, что двачеры редкостные говноеды и хуесосы. Ладно там гоблин скурвился, ва...\n",
      "TOXIC: : Блядь, хохлы, вы бы хоть с проксей писали, няши тупые....\n",
      "TOXIC: : По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засран...\n",
      "TOXIC: : Оп - хуесос и пидорас конченный, а его мать шлюха подзаборная....\n",
      "TOXIC: : Какие же хохлы всадники, пиздец просто....\n",
      "TOXIC: : Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло...\n",
      "\n",
      "F1 score for classifier \"LogisticRegression\" with \"CountVectorizer\" is 0.765702891326022\n",
      "The most toxic comments for this classifier are:\n",
      "\n",
      "TOXIC: : Хоть ты и дегенерат, но ты прав. В том, что ты грязноштанный потомок холопа, нет моей заслуги, лишь ...\n",
      "TOXIC: : Не зря, вас, хохлов, свиньями кличут. Вы и есть грязные животные, не способные к любви, привязанност...\n",
      "TOXIC: : Ты либо не знаешь правил русского языка либо шизофреник. Нет - предикатив, отрицающий факт существов...\n",
      "TOXIC: : Да не буду я тебе нихуя искать, общеизвестная инфа. В своих знаниях и так убежден, а если ты просто ...\n",
      "NON-TOXIC: Может вас просто собаки бесят?) меня не собаки бесят, а проявление агрессии.. Давить собак - проявля...\n",
      "TOXIC: : Нахуй иди чмо ебаное, рот твой ебал. Говна поешь, быдло...\n",
      "TOXIC: : ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ ...\n",
      "TOXIC: : В очередной раз убеждаюсь, что двачеры редкостные говноеды и хуесосы. Ладно там гоблин скурвился, ва...\n",
      "NON-TOXIC: та ну, хуйня это все про джентельменство . меня в свое время эти брачные игрища так сильно заебали, ...\n",
      "TOXIC: : По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засран...\n",
      "\n",
      "Comments found by all models:\n",
      "TOXIC: : По мексикански Флаг: Ублюдок, мать твою, а ну иди сюда говно собачье, решил меня поднять? Ты, засран...\n",
      "TOXIC: : ДА КАКОГО ЕБАНОГО ХУЯ МНЕ ТЕПЕРЬ ЮТУБ РЕКОМЕНДУЕТ ЕБУЧЕГО ШЕВЦОВА НАХУЙ СУКА БЛЯДЬ? Я КЛЯНУСЬ ЖОПОЙ ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from razdel import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "def run_model(vectorizer, classifier):\n",
    "    X_train = vectorizer.fit_transform(train.comment)\n",
    "    X_test = vectorizer.transform(test.comment)\n",
    "    y_train = train.toxic.values\n",
    "    y_test = test.toxic.values\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    print(f'F1 score for classifier \"{type(classifier).__name__}\" with \"{type(vectorizer).__name__}\" '\n",
    "          f'is {f1_score(y_test, predictions)}')\n",
    "    probabilities = classifier.predict_proba(X_test)\n",
    "    most_toxic_indices = probabilities[:, 1].argsort()[-10:]\n",
    "    # probabilities[:, 1] - извлекаем столбец с вероятностями токсичности\n",
    "    # argsort - сортируем, но получаем индексы, а не вероятности, которые нам не нужны\n",
    "    # [-10:] - отбираем 10 последних записей (так как сортировка по возрастанию)\n",
    "    most_toxic = set()\n",
    "    print(\"The most toxic comments for this classifier are:\\n\")\n",
    "    for i in most_toxic_indices:\n",
    "        entry = test.iloc[i]  # получаем элемент из тестовой выборки по индексу\n",
    "        output_message = f'{\"TOXIC: \" if entry.toxic else \"NON-TOXIC\"}: {entry.comment.strip()[:100]}...'\n",
    "        # обрезаем слишком длинные комментарии\n",
    "        print(output_message)\n",
    "        most_toxic.add(output_message)\n",
    "    print()\n",
    "    return most_toxic\n",
    "\n",
    "\n",
    "data = pd.read_csv('labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=0)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.6, ngram_range=(1, 2), stop_words=stopwords.words('russian'),\n",
    "                                   tokenizer=lambda stream: [token.text for token in tokenize(stream) if\n",
    "                                                             token.text not in punctuation])\n",
    "count_vectorizer = CountVectorizer(min_df=5, max_df=0.6, ngram_range=(1, 2), stop_words=stopwords.words('russian'),\n",
    "                                   tokenizer=lambda stream: [token.text for token in tokenize(stream) if\n",
    "                                                             token.text not in punctuation])\n",
    "naive_bayes = MultinomialNB(fit_prior=False, alpha=1.1)\n",
    "logistic_regression = LogisticRegression(class_weight='balanced', max_iter=200)\n",
    "# запускал 4 комбинации,так как по двум непонятно, чем объясняются разные результаты: классификатором или векторайзером\n",
    "most_toxic_comments = [result for result in [run_model(vectorizer=count_vectorizer, classifier=naive_bayes),\n",
    "                                             run_model(vectorizer=tfidf_vectorizer, classifier=logistic_regression),\n",
    "                                             run_model(vectorizer=tfidf_vectorizer, classifier=naive_bayes),\n",
    "                                             run_model(vectorizer=count_vectorizer, classifier=logistic_regression)]]\n",
    "print(\"Comments found by all models:\")\n",
    "for comment in set.intersection(*most_toxic_comments):\n",
    "    print(comment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5692050c",
   "metadata": {},
   "source": [
    "В целом, можно заметить, что результаты на разных моделях отличаются. \"Единодушно\" самым токсичным было определено только два коментария. Заметим, модели на основе TF-IDF Vectorizer безошибочно отнесли комментарии в число самых токсичных (как в байесовском классификаторе, так и в логистической регрессии). А вот модели на CountVectorizer отнесли в число самых токсичных по 2-3 обычных комментария. Можно заметить, что эти ошибочные комментарии также содержат грубую лексику, поэтому ошибка объяснима. Однако, отнесение этих примеров к \"самым токсичным\" наводит на мысль, что TF-IDF Vectorizer в этом плане гораздо эффективнее (если он решил, что текст токсичный, значит, так оно и есть)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde5ae2e",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab52a4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most important words for DecisionTreeClassifier:\n",
      "['тебе', 'хохлы', 'хохлов', 'нахуй', 'например'] \n",
      "\n",
      "Most important words for RandomForestClassifier:\n",
      "['хохлы', 'тебе', 'хохлов', 'нахуй', 'блядь'] \n",
      "\n",
      "Most important words for LogisticRegression:\n",
      "['хохлов', 'хохлы', 'дебил', 'русских', 'сука'] \n",
      "\n",
      "Most important words for MultinomialNB:\n",
      "['тебе', 'хохлы', 'хохлов', 'нахуй', 'хуй'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def run_model(vectorizer, classifier):\n",
    "    X_train = vectorizer.fit_transform(train.comment)\n",
    "    y_train = train.toxic.values\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier_name = type(classifier).__name__\n",
    "    inverse_vocabulary = {value: key for key, value in vectorizer.vocabulary_.items()}  # для удобства поиска по индексу\n",
    "    # поменяем местами индексы и слова\n",
    "    print(f'Most important words for {classifier_name}:')\n",
    "    most_important_features = []\n",
    "    if classifier_name == 'LogisticRegression':\n",
    "        most_important_features = classifier.coef_[0].argsort()[-1:-6:-1]\n",
    "        # classifier.coef_[0] - извлекаем таблицу важности признаков\n",
    "        # argsort - сортируем и сразу получаем индексы\n",
    "        # [-1:-6:-1] - берем последние 5 элементов (так как сортировка по возрастанию) в перевернутом виде (чтобы самое\n",
    "        # важное слово было первым)\n",
    "    elif classifier_name == 'MultinomialNB':\n",
    "        most_important_features = classifier.feature_log_prob_[1].argsort()[-1:-6:-1]\n",
    "    elif classifier_name in ['RandomForestClassifier', 'DecisionTreeClassifier']:\n",
    "        most_important_features = classifier.feature_importances_.argsort()[-1:-6:-1]\n",
    "    print([inverse_vocabulary[feature_index] for feature_index in most_important_features], \"\\n\")\n",
    "\n",
    "\n",
    "data = pd.read_csv('labeled.csv')\n",
    "train, test = train_test_split(data, test_size=0.1, random_state=0)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=40, max_df=0.025, stop_words=stopwords.words('russian'), ngram_range=(1, 3))\n",
    "models = [DecisionTreeClassifier(class_weight='balanced'),\n",
    "          RandomForestClassifier(),\n",
    "          LogisticRegression(class_weight='balanced'),\n",
    "          MultinomialNB(fit_prior=False)]\n",
    "for model in models:\n",
    "    run_model(vectorizer=tfidf_vectorizer, classifier=model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
