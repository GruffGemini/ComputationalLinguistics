{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe27361",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b18e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['будут', 'отправятся']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Зонды будут запущены в космос в 2029 году и отправятся ко второй точке Лагранжа в системе Солнце\"\n",
    "\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "parsed = [morph.parse(i) for i in text.split()]\n",
    "verbs = [i[0].word for i in parsed if i[0].tag.POS == 'VERB']\n",
    "verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de018fa",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09eed0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get(\n",
    "    'https://raw.githubusercontent.com/mannefedov/compling_nlp_hse_course/master/data/anna_karenina.txt'\n",
    ")\n",
    "\n",
    "# работайте с этими предложениями\n",
    "sentences = r.text.split('\\n')\n",
    "sentences = [sent for sent in sentences if len(sent) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06e45aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('вырождается', 0.19671514407338786),\n",
       " ('устои', 0.19671514407338786),\n",
       " ('ослабевают', 0.19671514407338786),\n",
       " ('нравы', 0.19671514407338786),\n",
       " ('падают', 0.19671514407338786),\n",
       " ('буржуазного', 0.19671514407338786),\n",
       " ('натиском', 0.19671514407338786),\n",
       " ('уклада', 0.19671514407338786),\n",
       " ('патриархального', 0.19671514407338786),\n",
       " ('рушатся', 0.19671514407338786),\n",
       " ('страницах', 0.19671514407338786),\n",
       " ('приметами', 0.19671514407338786),\n",
       " ('насыщенное', 0.19671514407338786),\n",
       " ('остропроблемное', 0.19671514407338786),\n",
       " ('психологически', 0.19671514407338786),\n",
       " ('аристократия', 0.18807778290532548),\n",
       " ('прогресса', 0.18807778290532548),\n",
       " ('произведения', 0.18807778290532548),\n",
       " ('утонченное', 0.18807778290532548),\n",
       " ('остатки', 0.1819494776291046),\n",
       " ('произведение', 0.1819494776291046),\n",
       " ('сложное', 0.1819494776291046),\n",
       " ('толстой', 0.17331211646104222),\n",
       " ('показывает', 0.1700283441478517),\n",
       " ('семейные', 0.16243032831667098),\n",
       " ('россии', 0.13832880029899972),\n",
       " ('каренина', 0.1318596500912228),\n",
       " ('времени', 0.12128437592213807),\n",
       " ('как', 0.10254114162968206),\n",
       " ('под', 0.10004588423276102),\n",
       " ('жизни', 0.09850793329775373),\n",
       " ('анна', 0.08152965818592199),\n",
       " ('это', 0.0550210069981116),\n",
       " ('на', 0.04767910703476529)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(sentences)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "feature_index = matrix[0,:].nonzero()[1]\n",
    "tfidf_scores = zip(feature_index, [matrix[0, x] for x in feature_index])\n",
    "\n",
    "d = {word:score for word,score in [(feature_names[i], score) for (i, score) in tfidf_scores]}\n",
    "sorted(d.items(), key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4aae7",
   "metadata": {},
   "source": [
    "# Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad2b2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "import gensim\n",
    "from collections import Counter\n",
    "\n",
    "sentences = [i.lower() for i in sentences]\n",
    "tokens = list(razdel.tokenize(i) for i in sentences)\n",
    "texts = []\n",
    "for i in tokens:\n",
    "    texts.append([j.text for j in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e504d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams\n",
    "counter = Counter()\n",
    "for i in texts:\n",
    "    counter.update(i)\n",
    "    counter.update(bigrams(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "289bb7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('красный', 'мешочек'), 5),\n",
       " (('красный', 'огонь'), 1),\n",
       " (('красный', ','), 2),\n",
       " (('красный', 'платок'), 1),\n",
       " (('красный', '.'), 1)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continuations = [(word, counter[word]) for word in counter if word[0] == 'красный']\n",
    "continuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d189c58d",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e82b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"решение\",\"ршеение\",\"ренешик\",\"рещиние\",\"ришение\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff072d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('решение', 'ршеение'), ('ршеение', 'решение')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textdistance\n",
    "lev = {}\n",
    "d_lev = {}\n",
    "for i in words:\n",
    "    for j in words:\n",
    "        d_lev[(i,j)] = textdistance.damerau_levenshtein(i, j)\n",
    "        lev[(i,j)] = textdistance.levenshtein(i, j)\n",
    "diff = [i for i in lev if lev[i] != d_lev[i]]\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668257ed",
   "metadata": {},
   "source": [
    "# Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac7400c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f42ddbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (645 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "text_ids = [tokenizer.encode(i) for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ef210a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for i in text_ids:\n",
    "    texts.append([tokenizer.decode(x) for x in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae4d1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = gensim.models.FastText(texts, vector_size=300, window=5, min_n=2, max_n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8f8cea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('##ка', 0.6319170594215393),\n",
       " ('а', 0.5129663944244385),\n",
       " ('##на', 0.4239211678504944),\n",
       " ('##ович', 0.40852585434913635),\n",
       " ('с', 0.2575743794441223),\n",
       " ('##евич', 0.23129010200500488),\n",
       " ('–', 0.22807161509990692),\n",
       " ('ф', 0.20572644472122192),\n",
       " ('##а', 0.19247445464134216),\n",
       " ('[SEP]', 0.1807914525270462)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('каренина')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0e282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
