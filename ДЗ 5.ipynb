{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671cba0a",
   "metadata": {},
   "source": [
    "# Домашнее задание № 5. Матричные разложения/Тематическое моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c01ac",
   "metadata": {},
   "source": [
    "## Задание № 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf903c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from string import punctuation\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word]\n",
    "    normalized_text = [morph.parse(word)[0].normal_form for word in normalized_text]\n",
    "    return ' '.join(normalized_text)\n",
    "\n",
    "\n",
    "def eval_table(x, y, pipeline, n=6):\n",
    "    labels = list(set(y))\n",
    "    fold_metrics = pd.DataFrame(index=labels)\n",
    "    errors = np.zeros((len(labels), len(labels)))\n",
    "    kfold = StratifiedKFold(n_splits=n, shuffle=True)\n",
    "    for i, (train_index, test_index) in enumerate(kfold.split(x, y)):\n",
    "        pipeline.fit(x[train_index], y[train_index])\n",
    "        preds = pipeline.predict(x[test_index])\n",
    "        fold_metrics[f'precision_{i}'] = precision_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'recall_{i}'] = recall_score(y[test_index], preds, labels=labels, average=None)\n",
    "        fold_metrics[f'f1_{i}'] = f1_score(y[test_index], preds, labels=labels, average=None)\n",
    "        errors += confusion_matrix(y[test_index], preds, labels=labels, normalize='true')\n",
    "    result = pd.DataFrame(index=labels)\n",
    "    result['precision'] = fold_metrics[[f'precision_{i}' for i in range(n)]].mean(axis=1)\n",
    "    result['precision_std'] = fold_metrics[[f'precision_{i}' for i in range(n)]].std(axis=1)\n",
    "    result['recall'] = fold_metrics[[f'recall_{i}' for i in range(n)]].mean(axis=1)\n",
    "    result['recall_std'] = fold_metrics[[f'recall_{i}' for i in range(n)]].std(axis=1)\n",
    "    result['f1'] = fold_metrics[[f'f1_{i}' for i in range(n)]].mean(axis=1)\n",
    "    result['f1_std'] = fold_metrics[[f'f1_{i}' for i in range(n)]].std(axis=1)\n",
    "    result.loc['mean'] = result.mean()\n",
    "    errors /= n\n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21d3e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('avito_category_classification.csv')\n",
    "data['description_norm'] = data['description'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb463eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline svd-sgd (1 out of 10). Mean f1 for pipeline svd-sgd is 0.758. Time elapsed: 0:00:51.132193\n",
      "Running pipeline svd-kneighbors (2 out of 10). Mean f1 for pipeline svd-kneighbors is 0.471. Time elapsed: 0:00:51.702201\n",
      "Running pipeline svd-bayes (3 out of 10). Mean f1 for pipeline svd-bayes is 0.111. Time elapsed: 0:00:45.568738\n",
      "Running pipeline svd-randomforest (4 out of 10). Mean f1 for pipeline svd-randomforest is 0.641. Time elapsed: 0:02:43.349817\n",
      "Running pipeline svd-extratrees (5 out of 10). Mean f1 for pipeline svd-extratrees is 0.623. Time elapsed: 0:01:37.652297\n",
      "Running pipeline nmf-sgd (6 out of 10). Mean f1 for pipeline nmf-sgd is 0.509. Time elapsed: 0:03:41.600246\n",
      "Running pipeline nmf-kneighbors (7 out of 10). Mean f1 for pipeline nmf-kneighbors is 0.507. Time elapsed: 0:04:09.596917\n",
      "Running pipeline nmf-bayes (8 out of 10). Mean f1 for pipeline nmf-bayes is 0.527. Time elapsed: 0:03:17.353888\n",
      "Running pipeline nmf-randomforest (9 out of 10). Mean f1 for pipeline nmf-randomforest is 0.709. Time elapsed: 0:03:35.775225\n",
      "Running pipeline nmf-extratrees (10 out of 10). Mean f1 for pipeline nmf-extratrees is 0.722. Time elapsed: 0:04:28.617629\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=5, max_df=0.6, ngram_range=(1, 2), stop_words=stopwords.words('russian'),\n",
    "                             tokenizer=lambda x: x.split())\n",
    "X_sparse = vectorizer.fit_transform(data['description_norm'])\n",
    "svd = TruncatedSVD(500)\n",
    "pipelines = {'svd-sgd': Pipeline([('vec', vectorizer), ('decomp', svd), ('clf', SGDClassifier())]),\n",
    "             'svd-kneighbors': Pipeline([('vec', vectorizer), ('decomp', svd), ('clf', KNeighborsClassifier())]),\n",
    "             'svd-bayes': Pipeline([('vec', vectorizer), ('decomp', svd), ('scaling', MinMaxScaler()), \n",
    "                                    ('clf', MultinomialNB())]),\n",
    "             'svd-randomforest': Pipeline([('vec', vectorizer), ('decomp', svd), ('clf', RandomForestClassifier())]),\n",
    "             'svd-extratrees': Pipeline([('vec', vectorizer), ('decomp', svd), ('clf', ExtraTreesClassifier())]),\n",
    "             'nmf-sgd': Pipeline([('vec', vectorizer), ('decomp', NMF(100)), ('clf', SGDClassifier())]),\n",
    "             'nmf-kneighbors': Pipeline([('vec', vectorizer), ('decomp', NMF(100)), ('clf', KNeighborsClassifier())]),\n",
    "             'nmf-bayes': Pipeline([('vec', vectorizer), ('decomp', NMF(100)), ('scaling', MinMaxScaler()),\n",
    "                                    ('clf', MultinomialNB())]),\n",
    "             'nmf-randomforest': Pipeline([('vec', vectorizer), ('decomp', NMF(100)), ('clf', RandomForestClassifier())]),\n",
    "             'nmf-extratrees': Pipeline([('vec', vectorizer), ('decomp', NMF(100)), ('clf', ExtraTreesClassifier())])}\n",
    "for count, pipe in enumerate(pipelines):\n",
    "    print(f'Running pipeline {pipe} ({count + 1} out of {len(pipelines)}). ', end='')\n",
    "    start = datetime.now()\n",
    "    metrics_svd, errors_svd = eval_table(data['description_norm'], data['category_name'], pipelines[pipe])\n",
    "    print(f'Mean f1 for pipeline {pipe} is {metrics_svd.loc[\"mean\"][\"f1\"].round(3)}. Time elapsed: {datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c352c4",
   "metadata": {},
   "source": [
    "Если взять за основной критерий среднее значение F1, лучшее сочетание - это SVD разложение и SGD классификатор. Кроме того, этот способ один из самых лучших по скорости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7833f61",
   "metadata": {},
   "source": [
    "## Задание № 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9175a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "punctuation = string.punctuation + '—«»…'\n",
    "num_topics = 20\n",
    "\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    normalized_text = [morph.parse(word.text.strip(punctuation).lower())[0].normal_form for word in\n",
    "                       razdel_tokenize(text) if word.text.strip(punctuation)]\n",
    "    return ' '.join(normalized_text)\n",
    "\n",
    "\n",
    "def perplexity(model: LdaMulticore, corpus: list) -> float:\n",
    "    return np.exp2(-model.log_perplexity(corpus))\n",
    "\n",
    "\n",
    "def coherence(model: LdaMulticore, texts: list, dictionary: gensim.corpora.Dictionary):\n",
    "    topics = []\n",
    "    for topic_id, topic in model.show_topics(num_topics=num_topics, formatted=False):\n",
    "        topic = [word for word, _ in topic]\n",
    "        topics.append(topic)\n",
    "    coherence_model_lda = gensim.models.CoherenceModel(topics=topics,\n",
    "                                                       texts=texts,\n",
    "                                                       dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "\n",
    "def print_model_report(model, corpus, texts, dictionary):\n",
    "    print('Topics:')\n",
    "    print(*[re.findall('\"(.+?)\"', i[1]) for i in model.print_topics()], sep='\\n')\n",
    "    print(f'Perplexity = {perplexity(model, corpus)}')\n",
    "    print(f'Coherence = {coherence(model, texts, dictionary)}')\n",
    "\n",
    "\n",
    "def run_simple_lda(texts):\n",
    "    simple_dictionary = gensim.corpora.Dictionary((text.split() for text in texts))\n",
    "    simple_dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "    simple_dictionary.compactify()\n",
    "    simple_corpus = [simple_dictionary.doc2bow(text.split()) for text in texts]\n",
    "    simple_lda = gensim.models.LdaMulticore(simple_corpus, num_topics, alpha='asymmetric', id2word=simple_dictionary,\n",
    "                                            passes=10)\n",
    "    print_model_report(simple_lda, simple_corpus, [text.split() for text in texts], simple_dictionary)\n",
    "\n",
    "\n",
    "def run_lda_with_ngrams(texts):\n",
    "    texts = [text.split() for text in texts]\n",
    "    phrases = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4)\n",
    "    phraser = gensim.models.phrases.Phraser(phrases)\n",
    "    ngrammed_texts = [text for text in phraser[texts]]\n",
    "    ngrammed_dictionary = gensim.corpora.Dictionary(ngrammed_texts)\n",
    "    ngrammed_dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "    ngrammed_dictionary.compactify()\n",
    "    ngrammed_corpus = [ngrammed_dictionary.doc2bow(text) for text in ngrammed_texts]\n",
    "    lda_with_ngrams = gensim.models.LdaMulticore(ngrammed_corpus, num_topics, alpha='asymmetric',\n",
    "                                                 id2word=ngrammed_dictionary, passes=10)\n",
    "    print_model_report(lda_with_ngrams, ngrammed_corpus, ngrammed_texts, ngrammed_dictionary)\n",
    "\n",
    "\n",
    "def run_lda_with_tf_idf(texts):\n",
    "    simple_dictionary = gensim.corpora.Dictionary((text.split() for text in texts))\n",
    "    simple_dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "    simple_dictionary.compactify()\n",
    "    simple_corpus = [simple_dictionary.doc2bow(text.split()) for text in texts]\n",
    "    tfidf = gensim.models.TfidfModel(simple_corpus, id2word=simple_dictionary)\n",
    "    tf_idf_corpus = tfidf[simple_corpus]\n",
    "    simple_lda = gensim.models.LdaMulticore(tf_idf_corpus, num_topics, alpha='asymmetric', id2word=simple_dictionary,\n",
    "                                            passes=10)\n",
    "    print_model_report(simple_lda, tf_idf_corpus, [text.split() for text in texts], simple_dictionary)\n",
    "\n",
    "\n",
    "def run_uber_lda(texts):\n",
    "    texts = [text.split() for text in texts]\n",
    "    phrases = gensim.models.Phrases(texts, scoring='npmi', threshold=0.4)\n",
    "    phraser = gensim.models.phrases.Phraser(phrases)\n",
    "    ngrammed_texts = [text for text in phraser[texts]]\n",
    "    ngrammed_dictionary = gensim.corpora.Dictionary(ngrammed_texts)\n",
    "    ngrammed_dictionary.filter_extremes(no_above=0.1, no_below=10)\n",
    "    ngrammed_dictionary.compactify()\n",
    "    ngrammed_corpus = [ngrammed_dictionary.doc2bow(text) for text in ngrammed_texts]\n",
    "    tfidf = gensim.models.TfidfModel(ngrammed_corpus, id2word=ngrammed_dictionary)\n",
    "    tf_idf_corpus = tfidf[ngrammed_corpus]\n",
    "    lda_with_ngrams = gensim.models.LdaMulticore(tf_idf_corpus, num_topics, alpha='asymmetric',\n",
    "                                                 id2word=ngrammed_dictionary, passes=10)\n",
    "    print_model_report(lda_with_ngrams, tf_idf_corpus, ngrammed_texts, ngrammed_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1c84214",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = open('wiki_data.txt', encoding='utf-8-sig').read().splitlines()[:1000]\n",
    "normalized_texts = [normalize(text) for text in raw_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40c9236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "['г', 'день', 'регион', 'праздник', 'метод', 'век', 'компания', 'святой', 'период', 'процесс']\n",
      "['животное', 'чтобы', 'друг', 'использовать', 'есть', 'если', 'образ', 'жизнь', 'можно', 'земля']\n",
      "['команда', 'матч', 'сезон', 'чемпионат', 'клуб', 'выиграть', 'кубок', 'турнир', 'победа', 'чемпион']\n",
      "['канада', 'корабль', 'национальный', 'программа', 'университет', 'провинция', 'космический', 'округ', 'версия', 'аэропорт']\n",
      "['альбом', 'песня', 'длина', 'семейство', 'смотреть', 'мм', 'американский', 'сын', 'род', 'де']\n",
      "['остров', 'россия', 'экономический', 'общество', 'метр', 'километр', 'проект', 'развитие', 'земля', 'г']\n",
      "['собор', 'система', 'станция', 'монастырь', 'атлетика', 'кладбище', 'орудие', 'тяжёлый', 'боливия', 'строительство']\n",
      "['доктор', 'село', 'река', 'харьковский', 'км', 'серия', '7', 'совет', 's', 'штат']\n",
      "['уезд', 'губерния', 'спортсмен', 'нижегородский', 'гонка', 'волость', 'венесуэла', '2000', 'раунд', '1996']\n",
      "['суд', 'газета', 'рим', 'день', 'дело', 'советский', 'декабрь', 'италия', 'н', 'эсминец']\n",
      "['посёлок', 'село', 'км', 'дом', 'поселение', 'церковь', 'сельский', 'здание', 'житель', 'иметься']\n",
      "['фильм', 'департамент', 'роль', 'км²', 'жужевать', 'барселона', 'театр', 'провинция', '’', 'актёр']\n",
      "['музей', 'дом', 'н', 'художник', 'дворец', 'здание', 'искусство', 'проект', 'москва', 'проведение']\n",
      "['корабль', 'лодка', 'флот', 'сила', 'корпус', 'боевой', 'система', 'море', 'морской', 'военно-морской']\n",
      "['член', 'убить', 'депутат', 'дело', 'партия', 'б', 'политический', 'председатель', 'государственный', 'право']\n",
      "['южный', 'премия', 'тысяча', 'данные', 'перепись', 'футбол', 'азербайджан', '500', 'тыс', 'дистанция']\n",
      "['спортсмен', 'соревнование', 'экипаж', 'серебряный', 'заезд', 'финал', 'бронзовый', 'ямайка', 'мужчина', 'бельгия']\n",
      "['религиозный', 'передача', 'организация', 'здание', 'закон', 'россия', 'церковь', '2010', 'объект', 'культура']\n",
      "['ссср', 'епархия', 'г', 'институт', 'академия', 'окончить', 'совет', 'московский', 'епископ', 'кафедра']\n",
      "['уезд', 'армия', 'округ', 'университет', 'войско', 'дивизия', 'военный', '1941', 'городской', 'корпус']\n",
      "Perplexity = 160.36276776973926\n",
      "Coherence = 0.4595014311374802\n"
     ]
    }
   ],
   "source": [
    "run_simple_lda(normalized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09e11e2",
   "metadata": {},
   "source": [
    "['команда', 'матч', 'сезон', 'чемпионат', 'клуб', 'выиграть', 'кубок', 'турнир', 'победа', 'чемпион'] - идеальная тема, все слова связаны, лишних нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e241b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "['остров', 'ни_один', 'не_завоевать', 'история_но', 'страна_представлять', 'медаль_сборная', 'спортсмен', 'метр', 'медаль', 'тот_число']\n",
      "['клуб', 'зимний_олимпийский', 'король', 'сын', 'сборная', 'брат', 'контракт', 'команда', 'вернуться', 'де']\n",
      "['компания', 'канада', 'сша', 'ссср', 'предприятие', 'завод', 'посёлок', 'основать', 'м', 'корпус']\n",
      "['игра', 'село', 'население', 'течение', 'полёт', 'эксперимент', 'корабль', 'станция', 'на_расстояние', 'по_перепись']\n",
      "['департамент', 'аргентина', 'лагерь', 'национальный', 'украинский', 'против', 'суд', 'правительство', 'польский', 'ссср']\n",
      "['вид', 'км', 'длина', 'посёлок', 'день', 'смотреть', 'река', 'высота', 'население', 'мм']\n",
      "['матч', 'остров', 'сборная', 'зелёный', 'турнир', 'выиграть', 'семейство', 'счёт', 'ирландия', 'команда']\n",
      "['команда', 'спортсмен', 'игра', 'клуб', 'финал', 'матч', 'альбом', 'занять', 'сборная', 'сезон']\n",
      "['г', 'здание', 'дом', 'общество', 'церковь', 'университет', 'россия', 'кладбище', 'музей', 'построить']\n",
      "['уезд', 'древний', 'культура', 'животное', 'земля', 'э', 'до_н', '1-й', 'быть_создать', 'народ']\n",
      "['штат', 'сергей', 'завод', 'предприятие', 'владимир', 'представитель', 'процесс', 'улица', 'убийство', 'птица']\n",
      "['доктор', 'фильм', 'себя', 'жизнь', 'я', 'дом', 'мир', 'серия', 'чтобы', 'ребёнок']\n",
      "['епархия', 'корабль', 'флот', 'сила', 'церковь', 'храм', 'боевой', 'бой', 'советский', 'противник']\n",
      "['система', 'использовать', 'если', 'то', 'двигатель', 'случай', 'станция', 'использоваться', 'линия', 'компания']\n",
      "['животное', 'монастырь', 'исследование', 'научный', 'организация', 'учёный', 'метод', 'г', 'изучение', 'задача']\n",
      "['сезон', 'гонка', 'выиграть', 'победа', 'карьера', 'раз', 'круг', '500', 'занять', 'подряд']\n",
      "['корпус', 'дивизия', 'армия', 'полковник', 'командующий', 'соединение', 'командир', 'наградить', 'затем', 'июль']\n",
      "['уезд', 'село', 'губерния', 'область', 'волость', 'г', 'чел', 'округ', 'территория', 'сельский_поселение']\n",
      "['фильм', 'роль', 'театр', 'альбом', 'the', 'шоу', 'играть', 'актёр', 'песня', 'известный']\n",
      "['номер', 'хутор', 'дубовский_район', 'доска', 'переход', 'сын', 'поэт', 'свет', 'уровень', 'точка']\n",
      "Perplexity = 189.18823197211967\n",
      "Coherence = 0.49562550906055236\n"
     ]
    }
   ],
   "source": [
    "run_lda_with_ngrams(normalized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcaa852",
   "metadata": {},
   "source": [
    "По числовым показателям версия с n-граммами не лучше и не хуже обычной. \"На глаз\" в версии с n-граммами кажется больше удачных тем. Помимо спортивной, здесь ещё получилась удачная военная:\n",
    "['корпус', 'дивизия', 'армия', 'полковник', 'командующий', 'соединение', 'командир', 'наградить', 'затем', 'июль']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30a0d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "['остров', 'фильм', 'спортсмен', 'канада', 'соревнование', 'чемпионат', 'клуб', 'атлетика', 'зимний', 'экипаж']\n",
      "['село', 'уезд', 'значение', 'посёлок', 'река', 'харьковский', 'км', 'сельский', 'нижегородский', 'код']\n",
      "['департамент', 'жужевать', 'км²', 'аргентина', 'провинция', 'граничить', 'рост', 'плотность', 'муниципалитет', 'статистика']\n",
      "['б', 'секретарь', 'вкп', 'цк', 'атака', 'князь', 'совет', 'армия', 'село', 'чемпионат']\n",
      "['хутор', 'дубовский', 'ростовский', 'поселение', 'сельский', 'динамика', 'иметься', 'численность', 'верхний', 'изображение']\n",
      "['верховный', 'экипаж', 'лагерь', 'ссср', 'финал', 'корпус', 'бронзовый', 'король', 'заезд', 'село']\n",
      "['существо', 'остров', 'живой', 'иран', 'уезд', 'компания', 'концепция', 'роман', 'оскар', 'полёт']\n",
      "['сезон', 'лагерь', 'завод', 'тур', 'музей', 'совместно', 'парк', 'н', '№', 'кубок']\n",
      "['фотография', 'квартира', 'ночь', 'украина', 'уезд', 'фильм', 'старое', 'павел', 'подняться', 'нижегородский']\n",
      "['фамилия', 'испанский', 'итальянский', 'фильм', 'убить', 'обеспечивать', 'лес', 'дом', 'реализовать', 'деревня']\n",
      "['корабль', 'солнечный', 'превышать', 'камень', 'университет', 'символ', 'соревнование', 'хутор', '40', 'чемпионат']\n",
      "['ямайка', 'альбом', 'монастырь', 'заезд', 'собор', 'община', 'век', '’', 'башня', 'фон']\n",
      "['посёлок', 'харьковский', 'село', 'остров', 'клуб', 'совет', 'художник', 'крым', 'г', 'тур']\n",
      "['долина', 'компания', 'пролив', 'норвежский', 'река', 'можно', 'процесс', 'означать', 'сельсовет', 'популярный']\n",
      "['–', 'сельсовет', 'поселение', 'россия', 'опубликовать', 'муж', 'медицинский', 'врач', 'париж', 'италия']\n",
      "['поражение', 'нередко', 'глаз', 'автомобиль', 'км', 'ботсвана', '1965', 'редкий', 'узел', 'обычно']\n",
      "['церковь', 'матч', 'тур', '2019', 'режим', 'концерт', 'in', 'сцена', 'чемпионат', 'сыграть']\n",
      "['б', 'де', 'контракт', 'клуб', 'дебютировать', 'подписать', 'ii', 'против', 'матч', 'ворота']\n",
      "['посёлок', 'располагаться', 'иметься', 'житель', 'торговый', 'дом', 'нижегородский', 'завод', '1995', 'перевести']\n",
      "['альбом', 'песня', 'in', 'композитор', 'музыка', 'фильм', 'the', 'музыкальный', 'пилот', 'сказать']\n",
      "Perplexity = 617.8187961041224\n",
      "Coherence = 0.41047962693658196\n"
     ]
    }
   ],
   "source": [
    "run_lda_with_tf_idf(normalized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061d8144",
   "metadata": {},
   "source": [
    "По числовым показателям версия с TF-IDF уступает обоим предыдущим версиям. В целом, темы угадываются, но почти в каждой есть лишние слова. Самая удачная тема, пожалуй, музыкальная: ['альбом', 'песня', 'in', 'композитор', 'музыка', 'фильм', 'the', 'музыкальный', 'пилот', 'сказать']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f401de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics:\n",
      "['остров', 'фильм', 'уезд', 'значение', 'игра', 'канада', 'клуб', 'вид', 'г', 'спортсмен']\n",
      "['не_завоевать', 'история_но', 'ни_один', 'страна_представлять', 'медаль_сборная', 'зимний_олимпийский', 'медаль', 'венесуэла', 'игра_1992', 'женщина_принимать']\n",
      "['фамилия', 'метр_над', 'известный', 'испанский', 'итальянский', 'диаметр', 'семя', 'мексика', 'свободный', 'лист']\n",
      "['село', 'харьковский_область', 'по_перепись', 'посёлок', 'на_расстояние', 'сельский_совет', 'м_ж', '2001_год', 'код_коатуа', 'население']\n",
      "['пункт', 'железнодорожный', 'цветок', 'украина', 'сборник', 'литература', 'миссия', 'николай', 'село', 'км_к']\n",
      "['сфера', 'ты', 'сезон', 'доктор', 'спортсмен', 'игра', 'место_занятой', 'таблица', 'воздух', 'разработать']\n",
      "['региональный', 'регион', 'национальный', 'код_коатуа', 'автомобильный_дорога', 'м_ж', 'по_перепись', 'посёлок', 'железный_дорога', 'харьковский_область']\n",
      "['автомобиль', 'суд', 'круг', 'трасса', '1965_год', 'страна', 'альбом', 'фраза', 'финансовый', 'европейский']\n",
      "['тёмный', 'зал', 'спортсмен', 'соревнование_по', 'фильм', 'р', 'азербайджан', 'вид_спорт', 'польский', '1964']\n",
      "['село', 'область', 'залив', 'кладбище', 'критика', 'тёмный', 'обстановка', 'г', 'фильм', 'мирный']\n",
      "['анна', 'фильм', 'термин', 'песня', 'ремонт', 'роль', 'уничтожение', 'польский', 'понятие', 'событие']\n",
      "['китайский', 'изучать', 'музыка', 'произведение', 'писатель', 'учиться', 'фильм', 'роман', 'поместить', 'седьмой']\n",
      "['прежде_весь', 'птица', 'роль', 'житель', 'хозяйство', 'фильм', 'посёлок', 'актриса', 'путешествие', 'длина']\n",
      "['киргизия', 'атланта_сша', '33', 'игра_1996', 'один_медаль', 'завоевать_ни', 'сборная_страна', 'но_не', '1996', 'раз_за']\n",
      "['приём', 'посёлок', 'хозяйство', 'право_берег', 'опытный', 'по_перепись', 'житель', 'дорога', '1995_год', 'тело']\n",
      "['пол', 'телесериал', 'роль', 'шоу', 'ассоциация', '45', 'фильм', 'сняться', 'актёр', 'округ']\n",
      "['вид', 'парк', 'на_территория', 'территория', 'дерево', 'примерно', 'семейство', 'же', 'лондонский', '53']\n",
      "['монастырь', '1-й', 'собор', 'нижний', '1969', 'башня', 'верхний', 'должный_быть', '2-й', '1973']\n",
      "['страна_представлять', 'медаль_сборная', '3_женщина', 'фильм', 'сеул_корея', 'боливия_принимать', 'боливия', 'игра_1988', 'поселение', 'смерть']\n",
      "['корабль', 'миссия', 'двигатель', 'помощь', 'полёт', 'процесс', 'направление', 'тип', 'система', 'вооружение']\n",
      "Perplexity = 642.7696071192436\n",
      "Coherence = 0.4200901808313091\n"
     ]
    }
   ],
   "source": [
    "run_uber_lda(normalized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54353afc",
   "metadata": {},
   "source": [
    "Числовые показатели почти такие же, как и в обычной TF-IDF версии. На глаз получается тоже похоже на TF-IDF. Самые удачные темы - спортивные, например: ['не_завоевать', 'история_но', 'ни_один', 'страна_представлять', 'медаль_сборная', 'зимний_олимпийский', 'медаль', 'венесуэла', 'игра_1992', 'женщина_принимать']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b6a1e",
   "metadata": {},
   "source": [
    "#### В общем и целом, наиболее удачной, на мой взгляд, получилась версия с n-граммами без TF-IDF."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
