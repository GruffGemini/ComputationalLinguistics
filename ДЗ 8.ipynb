{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a-PJZvPehIkKyO0Ia_qhB58GoUyNtqeF",
      "authorship_tag": "ABX9TyPuFVi2qA+lYiVx5HpdGqn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GruffGemini/ComputationalLinguistics/blob/main/%D0%94%D0%97%208.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Домашнее задание № 8"
      ],
      "metadata": {
        "id": "VXIwe9GZGTQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 1"
      ],
      "metadata": {
        "id": "AZd4qYMNGbe2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rEqrHJKbFEAU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "punkt = punctuation + '«—»'\n",
        "ROOT_DIR = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(punkt) for token in tokens]\n",
        "    return [token for token in tokens if token and token not in punkt]"
      ],
      "metadata": {
        "id": "5hHQNBWPFPLO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(os.path.join(ROOT_DIR, 'lenta_40k.csv'))\n",
        "processed_texts = []\n",
        "vocab = Counter()\n",
        "for text in data.text:\n",
        "    processed_text = preprocess(text)\n",
        "    vocab.update(processed_text)\n",
        "    processed_texts.append(processed_text)"
      ],
      "metadata": {
        "id": "zoffZTlmFVOi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {'PAD': 0, 'UNK': 1}\n",
        "for word in vocab:\n",
        "    word2id[word] = len(word2id)\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "X = []\n",
        "for text in processed_texts:\n",
        "    ids = [word2id.get(token, 1) for token in text]\n",
        "    X.append(ids)\n",
        "MEAN_LEN = np.median([len(x) for x in X])\n",
        "MAX_LEN = int(MEAN_LEN + 30)\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)\n",
        "id2label = {i: label for i, label in enumerate(set(data.topic.values))}\n",
        "label2id = {l: i for i, l in id2label.items()}\n",
        "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
      ],
      "metadata": {
        "id": "n1r-oW9_GvNo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelData:\n",
        "  def __init__(self, model, name):\n",
        "    self.model = model\n",
        "    self.name = name\n",
        "    self.train_score = 0\n",
        "    self.val_score = 0"
      ],
      "metadata": {
        "id": "qRYWpCx6dIhL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем общие блоки для всех моделей"
      ],
      "metadata": {
        "id": "UWCInpt6EuID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=40)(inputs, )"
      ],
      "metadata": {
        "id": "VkuuN1ojG36p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(last_layer):\n",
        "  dense = tf.keras.layers.Dense(64, activation='relu')(last_layer)\n",
        "  outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n",
        "  return model"
      ],
      "metadata": {
        "id": "0EmyLs_KclFV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(model):\n",
        "  model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "         epochs=15)"
      ],
      "metadata": {
        "id": "YYA72mQfcu6K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь создадим несколько моделей. Для чистоты эксперимента везде пришлось взять число нейронов = 32. Это мало, но при большем числе нейронов не запускается модель с 50 слоями."
      ],
      "metadata": {
        "id": "Ok-gwxqDdoOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = []"
      ],
      "metadata": {
        "id": "cMNPuUw8dyDT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru = tf.keras.layers.GRU(32, return_sequences=False)(embeddings)\n",
        "models.append(ModelData(model=make_model(gru), name='1 слой GRU'))"
      ],
      "metadata": {
        "id": "-DzwoLyecHbE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = tf.keras.layers.LSTM(32, return_sequences=False)(embeddings)\n",
        "models.append(ModelData(model=make_model(lstm), name='1 слой LSTM'))"
      ],
      "metadata": {
        "id": "-8CMCp0jeUe3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru = tf.keras.layers.GRU(32, return_sequences=True)(embeddings)\n",
        "lstm = tf.keras.layers.LSTM(32, return_sequences=False)(gru)\n",
        "models.append(ModelData(model=make_model(lstm), name='1 GRU + LSTM'))"
      ],
      "metadata": {
        "id": "k6PEYVUAeapT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True))(embeddings)\n",
        "lstm1 = tf.keras.layers.LSTM(32, return_sequences=True)(bigru)\n",
        "lstm2 = tf.keras.layers.LSTM(32, return_sequences=False)(lstm1)\n",
        "models.append(ModelData(model=make_model(lstm2), name='BIGRU + 2 LSTM'))"
      ],
      "metadata": {
        "id": "8EPFgeine2pZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru = tf.keras.layers.GRU(32, return_sequences=True)(embeddings)\n",
        "for _ in range(4):\n",
        "  gru = tf.keras.layers.GRU(32, return_sequences=True)(gru)\n",
        "lstm1 = tf.keras.layers.LSTM(32, return_sequences=True)(gru)\n",
        "lstm2 = tf.keras.layers.LSTM(32, return_sequences=True)(lstm1)\n",
        "lstm3 = tf.keras.layers.LSTM(32, return_sequences=False)(lstm2)\n",
        "models.append(ModelData(model=make_model(lstm3), name='5 GRU + 3 LSTM'))"
      ],
      "metadata": {
        "id": "rQrAcaizfOkf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True),\n",
        "                                      backward_layer=tf.keras.layers.GRU(32, return_sequences=True,\n",
        "                                                                         go_backwards=True))(embeddings)\n",
        "bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=False),\n",
        "                                      backward_layer=tf.keras.layers.LSTM(32, return_sequences=False,\n",
        "                                                                         go_backwards=True))(bigru)\n",
        "models.append(ModelData(model=make_model(bilstm), name='BIGRU + BILSTM'))                                          "
      ],
      "metadata": {
        "id": "_A99Sz2dgJ67"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm1 = tf.keras.layers.LSTM(32, return_sequences=True)(embeddings)\n",
        "gru1 = tf.keras.layers.GRU(32, return_sequences=True)(lstm1)\n",
        "bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True))(gru1)\n",
        "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32, return_sequences=True))(bilstm)\n",
        "gru2 = tf.keras.layers.GRU(32, return_sequences=True)(bigru)\n",
        "lstm2 = tf.keras.layers.LSTM(32, return_sequences=False)(gru2)\n",
        "models.append(ModelData(model=make_model(lstm2), name='LSTM -> GRU -> BILSTM -> BIGRU -> GRU -> LSTM'))    "
      ],
      "metadata": {
        "id": "PX6OlF-phCc5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import choice\n",
        "layer = choice([tf.keras.layers.SimpleRNN(32, return_sequences=True)(embeddings),\n",
        "                 tf.keras.layers.LSTM(32, return_sequences=True)(embeddings),\n",
        "                 tf.keras.layers.GRU(32, return_sequences=True)(embeddings)])\n",
        "for _ in range(48):\n",
        "  layer = choice([tf.keras.layers.SimpleRNN(32, return_sequences=True)(layer),\n",
        "                 tf.keras.layers.LSTM(32, return_sequences=True)(layer),\n",
        "                 tf.keras.layers.GRU(32, return_sequences=True)(layer)])\n",
        "layer = choice([tf.keras.layers.SimpleRNN(32, return_sequences=False)(layer),\n",
        "                 tf.keras.layers.LSTM(32, return_sequences=False)(layer),\n",
        "                 tf.keras.layers.GRU(32, return_sequences=False)(layer)])\n",
        "models.append(ModelData(model=make_model(layer), name='50 random layers'))   "
      ],
      "metadata": {
        "id": "GUAmHLI5h7yb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим обучение"
      ],
      "metadata": {
        "id": "hIyKflhJE0we"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  print(model.name)\n",
        "  fit_model(model.model)"
      ],
      "metadata": {
        "id": "VaHsUnG-kBBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод опущен, так как его слишком много. Оценим итоговую f-меру моделей"
      ],
      "metadata": {
        "id": "CdsIqk_zE24T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  model.val_score = model.model.history.history['val_f1'][-1]\n",
        "  model.train_score = model.model.history.history['f1'][-1]\n",
        "sorted_models = sorted(models, key=lambda x: x.val_score, reverse=True)\n",
        "for model in sorted_models:\n",
        "  print(f'{model.name} - train={model.train_score} - val={model.val_score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAaZA4RUlvsq",
        "outputId": "55b5f812-6ba6-49e7-821f-5a1ed60ec70f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 слой LSTM - train=0.9956343173980713 - val=0.5349631905555725\n",
            "BIGRU + BILSTM - train=0.9966739416122437 - val=0.5271187424659729\n",
            "BIGRU + 2 LSTM - train=0.9968664646148682 - val=0.4976016581058502\n",
            "1 GRU + LSTM - train=0.9963577389717102 - val=0.491421103477478\n",
            "1 слой GRU - train=0.9897481203079224 - val=0.48922500014305115\n",
            "LSTM -> GRU -> BILSTM -> BIGRU -> GRU -> LSTM - train=0.9902581572532654 - val=0.47209644317626953\n",
            "5 GRU + 3 LSTM - train=0.9398456811904907 - val=0.44356808066368103\n",
            "50 random layers - train=0.0 - val=0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из результатов видно, что лучшая модель - самая простая с 1 слоем LSTM. Нагромождение слоёв не даёт прироста результата, а модель с 50 слоями вообще не работает адекватно (она вроде бы обучалась, но очень медленно, 15 эпох ей явно было мало)."
      ],
      "metadata": {
        "id": "yuqh6jnPFW-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Задание 2"
      ],
      "metadata": {
        "id": "f3tGgq-IGf44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install navec\n",
        "!pip install slovnet"
      ],
      "metadata": {
        "id": "59rFh0gNGjpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from navec import Navec\n",
        "from slovnet.model.emb import NavecEmbedding"
      ],
      "metadata": {
        "id": "RtFHnkpKG2t6"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"wikiann\", 'ru')"
      ],
      "metadata": {
        "id": "R9tcbzx-G5eQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter()\n",
        "for sent in dataset['train']['tokens']:\n",
        "  vocab.update([x.lower() for x in sent])\n",
        "word2id = {'<pad>':0, '<unk>':1}\n",
        "for word in vocab:\n",
        "    word2id[word] = len(word2id)\n",
        "id2word = {i:word for word, i in word2id.items()}\n",
        "X = []\n",
        "for sent in dataset['train']['tokens']:\n",
        "    tokens = [w.lower() for w in sent]\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)\n",
        "X_test = []\n",
        "for sent in dataset['test']['tokens']:\n",
        "    tokens = [w.lower() for w in sent]\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X_test.append(ids)\n",
        "MAX_LEN = max(len(x) for x in X)\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN, padding='post')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=MAX_LEN, padding='post')\n",
        "id2labels = {0:'O', 1:'B-PER', 2:'I-PER', 3:'B-ORG', 4:'I-ORG', 5: 'B-LOC', 6:'I-LOC', 7:'<pad>'}\n",
        "label2id = {v:k for k,v in id2labels.items()} \n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(dataset['train']['ner_tags'], value=7,\n",
        "                                                  maxlen=MAX_LEN,  padding='post')\n",
        "y_test = tf.keras.preprocessing.sequence.pad_sequences(dataset['test']['ner_tags'], value=7,\n",
        "                                                       maxlen=MAX_LEN,  padding='post')"
      ],
      "metadata": {
        "id": "8I_eikoRMNe_"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Используем предобученные эмбеддинги navec"
      ],
      "metadata": {
        "id": "gc9etybUZj4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "navec = Navec.load(os.path.join(ROOT_DIR, path))\n",
        "emb = NavecEmbedding(navec)\n",
        "num_tokens = len(vocab) + 2\n",
        "embedding_dim = 300\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for id in id2word:\n",
        "  try:\n",
        "    navec_id = navec.vocab[id2word[id]]\n",
        "    input = np.asarray(navec_id)    \n",
        "    embedding_vector = emb(input)\n",
        "  except KeyError:\n",
        "    embedding_vector = navec.vocab['<unk>']\n",
        "  embedding_matrix[id] = embedding_vector"
      ],
      "metadata": {
        "id": "ucBieZvgM4LR"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим Embedding слой на основе предобученных эмбеддингов"
      ],
      "metadata": {
        "id": "kf0Aj4z6Z3sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    num_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "7RWAy_GmUGUD"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим BILSTM модель"
      ],
      "metadata": {
        "id": "LT-3VNfzfwmv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = embedding_layer(inputs)\n",
        "\n",
        "bilstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embeddings)\n",
        "bilstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(bilstm_1)\n",
        "bilstm_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(bilstm_2)\n",
        "bilstm_4 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(bilstm_3)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(bilstm_4)\n",
        "\n",
        "bilstm_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "bilstm_model.compile(optimizer='adam',\n",
        "                     loss='sparse_categorical_crossentropy', \n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t38LxgGdORn3"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model.fit(X, y, \n",
        "                 validation_data=(X_test, y_test),\n",
        "                 batch_size=64,\n",
        "                 epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWpIRPReUgEv",
        "outputId": "03d9b8f8-168a-446d-dc9d-be4b6e323e33"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 26s 52ms/step - loss: 0.1450 - accuracy: 0.9578 - val_loss: 0.0862 - val_accuracy: 0.9716\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 16s 50ms/step - loss: 0.0602 - accuracy: 0.9812 - val_loss: 0.0658 - val_accuracy: 0.9782\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.0465 - accuracy: 0.9854 - val_loss: 0.0592 - val_accuracy: 0.9810\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 13s 43ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.0604 - val_accuracy: 0.9807\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0590 - val_accuracy: 0.9826\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86b25bd650>"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И BIGRU модель"
      ],
      "metadata": {
        "id": "AnY5W0uZgRJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = embedding_layer(inputs)\n",
        "\n",
        "bigru_1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
        "bigru_2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(bigru_1)\n",
        "bigru_3 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(bigru_2)\n",
        "bigru_4 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(bigru_3)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(bigru_4)\n",
        "\n",
        "bigru_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "bigru_model.compile(optimizer='adam',\n",
        "                     loss='sparse_categorical_crossentropy', \n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UxA8X2TDgUIy"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigru_model.fit(X, y, \n",
        "                 validation_data=(X_test, y_test),\n",
        "                 batch_size=64,\n",
        "                 epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxtYuSvrgWCn",
        "outputId": "6b6aa5ab-a071-48e2-9465-b015b9ea1545"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "313/313 [==============================] - 26s 50ms/step - loss: 0.1193 - accuracy: 0.9677 - val_loss: 0.0711 - val_accuracy: 0.9763\n",
            "Epoch 2/5\n",
            "313/313 [==============================] - 13s 41ms/step - loss: 0.0521 - accuracy: 0.9835 - val_loss: 0.0609 - val_accuracy: 0.9794\n",
            "Epoch 3/5\n",
            "313/313 [==============================] - 14s 43ms/step - loss: 0.0426 - accuracy: 0.9865 - val_loss: 0.0581 - val_accuracy: 0.9811\n",
            "Epoch 4/5\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.0547 - val_accuracy: 0.9821\n",
            "Epoch 5/5\n",
            "313/313 [==============================] - 13s 40ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0535 - val_accuracy: 0.9829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86a931d2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для BILSTM"
      ],
      "metadata": {
        "id": "Il81p_YFhT7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = bilstm_model.predict(X_test).argmax(2)\n",
        "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
        "                                                                     target_names=list(id2labels.values()),\n",
        "                                                                     zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM1NoVmGXcEz",
        "outputId": "a63ad061-ac5b-4afe-e311-78147763cd20"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.91      0.95      0.93     40480\n",
            "       B-PER       0.75      0.90      0.82      3542\n",
            "       I-PER       0.82      0.95      0.88      7544\n",
            "       B-ORG       0.65      0.65      0.65      4074\n",
            "       I-ORG       0.88      0.67      0.76      8008\n",
            "       B-LOC       0.82      0.71      0.76      4560\n",
            "       I-LOC       0.90      0.62      0.73      3060\n",
            "       <pad>       1.00      1.00      1.00    468732\n",
            "\n",
            "    accuracy                           0.98    540000\n",
            "   macro avg       0.84      0.81      0.82    540000\n",
            "weighted avg       0.98      0.98      0.98    540000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метрики для BIGRU"
      ],
      "metadata": {
        "id": "H9y09ErAhhnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "pred = bigru_model.predict(X_test).argmax(2)\n",
        "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
        "                                                                     target_names=list(id2labels.values()),\n",
        "                                                                     zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwoK1IbXhkkh",
        "outputId": "0fbedd1c-39d6-4c4b-8632-a9c766950354"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.92      0.93     40480\n",
            "       B-PER       0.79      0.90      0.84      3542\n",
            "       I-PER       0.83      0.95      0.89      7544\n",
            "       B-ORG       0.63      0.68      0.65      4074\n",
            "       I-ORG       0.84      0.73      0.78      8008\n",
            "       B-LOC       0.76      0.80      0.78      4560\n",
            "       I-LOC       0.75      0.76      0.75      3060\n",
            "       <pad>       1.00      1.00      1.00    468732\n",
            "\n",
            "    accuracy                           0.98    540000\n",
            "   macro avg       0.82      0.84      0.83    540000\n",
            "weighted avg       0.98      0.98      0.98    540000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "По метрикам BIGRU немного лучше"
      ],
      "metadata": {
        "id": "dsCHV3H1hsXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text, word2id):\n",
        "    # токенизирует и переводит в индексы\n",
        "    tokens = re.findall('\\w+|[^\\w\\s]+', text)\n",
        "    ids = [word2id.get(token.lower(), 1) for token in tokens]\n",
        "    return tokens, ids\n",
        "\n",
        "def pred2tags(pred, id2label, length):\n",
        "    # декодирует индексы в части речи\n",
        "    # length нужно чтобы откидывать паддинги или некорректные предсказания\n",
        "    pred = pred.argmax(2)[0, :length]\n",
        "    labels = [id2label[l] for l in pred]\n",
        "    return labels\n",
        "\n",
        "def label_seq(text, word2id, id2label, max_len, model):\n",
        "    tokens, ids = tokenize(text, word2id)\n",
        "    pred = model.predict(tf.keras.preprocessing.sequence.pad_sequences([ids], \n",
        "                                                                       maxlen=max_len, \n",
        "                                                                       padding='post'))\n",
        "    labels = pred2tags(pred, id2label, len(ids))\n",
        "    \n",
        "    return list(zip(tokens, labels))"
      ],
      "metadata": {
        "id": "A79Tai4DX775"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем сравнить модели на предложениях"
      ],
      "metadata": {
        "id": "7YCVdVyJiGer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare(sentence):\n",
        "  print('BILSTM')\n",
        "  print(label_seq(sentence, word2id, id2labels, MAX_LEN, bilstm_model))\n",
        "  print('BIGRU')\n",
        "  print(label_seq(sentence, word2id, id2labels, MAX_LEN, bigru_model))"
      ],
      "metadata": {
        "id": "A_UfGfKQlYzL"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare('Алексей сказал Светлане, чтобы она собиралась на поезд в Москву.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8wnV5r-X_an",
        "outputId": "5491aba2-fa75-4613-95b7-f2bb1a9389af"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILSTM\n",
            "[('Алексей', 'B-PER'), ('сказал', 'I-PER'), ('Светлане', 'I-PER'), (',', 'O'), ('чтобы', 'O'), ('она', 'O'), ('собиралась', 'O'), ('на', 'O'), ('поезд', 'O'), ('в', 'O'), ('Москву', 'B-LOC'), ('.', 'O')]\n",
            "BIGRU\n",
            "[('Алексей', 'B-PER'), ('сказал', 'I-PER'), ('Светлане', 'I-PER'), (',', 'O'), ('чтобы', 'O'), ('она', 'O'), ('собиралась', 'O'), ('на', 'O'), ('поезд', 'O'), ('в', 'O'), ('Москву', 'B-LOC'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Идентичные результаты"
      ],
      "metadata": {
        "id": "1-k9rESHipac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare('Я поступил в ВШЭ в Питере')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXd4Ie_mYOBT",
        "outputId": "e8768e79-e673-461c-eada-e8a9eefa81f1"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILSTM\n",
            "[('Я', 'O'), ('поступил', 'O'), ('в', 'O'), ('ВШЭ', 'B-ORG'), ('в', 'O'), ('Питере', 'B-ORG')]\n",
            "BIGRU\n",
            "[('Я', 'O'), ('поступил', 'O'), ('в', 'O'), ('ВШЭ', 'B-ORG'), ('в', 'I-ORG'), ('Питере', 'B-LOC')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У обеих моделях по одной ошибке в разных местах"
      ],
      "metadata": {
        "id": "ijVZbFFJir8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare('Виктор, Семен, Петр, Арагорн')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNdFO6viYRnT",
        "outputId": "c67b43d4-ade3-4715-d47a-543ce3928fe4"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILSTM\n",
            "[('Виктор', 'B-PER'), (',', 'I-PER'), ('Семен', 'I-PER'), (',', 'O'), ('Петр', 'I-PER'), (',', 'I-PER'), ('Арагорн', 'I-PER')]\n",
            "BIGRU\n",
            "[('Виктор', 'B-PER'), (',', 'I-PER'), ('Семен', 'I-PER'), (',', 'I-PER'), ('Петр', 'I-PER'), (',', 'I-PER'), ('Арагорн', 'I-PER')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BILSTM посчитал \"Виктор, Семен\" за одну сущность, \"Петр, Арагорн\" - за другую\n",
        "\n",
        "BIGRU объединил в одну сущность все имена"
      ],
      "metadata": {
        "id": "CBBahP3cjI6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare('Президент Международного олимпийского комитета Томас Бах объявил зимние Олимпийские игры 2022 года закрытыми.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JH8MxJrSlWs-",
        "outputId": "904c946c-88ab-41d4-9ba2-49c1964596de"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILSTM\n",
            "[('Президент', 'O'), ('Международного', 'B-ORG'), ('олимпийского', 'I-ORG'), ('комитета', 'O'), ('Томас', 'B-PER'), ('Бах', 'I-PER'), ('объявил', 'O'), ('зимние', 'B-ORG'), ('Олимпийские', 'I-ORG'), ('игры', 'O'), ('2022', 'B-ORG'), ('года', 'I-ORG'), ('закрытыми', 'I-ORG'), ('.', 'O')]\n",
            "BIGRU\n",
            "[('Президент', 'O'), ('Международного', 'B-ORG'), ('олимпийского', 'I-ORG'), ('комитета', 'I-ORG'), ('Томас', 'B-PER'), ('Бах', 'I-PER'), ('объявил', 'O'), ('зимние', 'B-ORG'), ('Олимпийские', 'I-ORG'), ('игры', 'O'), ('2022', 'B-ORG'), ('года', 'I-ORG'), ('закрытыми', 'I-ORG'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь BIGRU отработала удачнее, корректно определив организацию \"Международного олимпийского комитета\". Однако обе модели ошибочно отнесли к организациям фразы в конце предложения."
      ],
      "metadata": {
        "id": "DLEn3mwsnh0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare('Бывший нападающий «Динамо» Сильвестр Игбун подписал контракт с «Нижним Новгородом». Об этом «Спорт-Экспрессу» сообщил генеральный директор клуба Равиль Измайлов.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG5gn0VxnzII",
        "outputId": "4140f6d2-0559-4e1e-eb8d-97956ac30ec1"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILSTM\n",
            "[('Бывший', 'O'), ('нападающий', 'O'), ('«', 'O'), ('Динамо', 'B-ORG'), ('»', 'O'), ('Сильвестр', 'B-PER'), ('Игбун', 'I-PER'), ('подписал', 'O'), ('контракт', 'O'), ('с', 'O'), ('«', 'O'), ('Нижним', 'B-PER'), ('Новгородом', 'I-PER'), ('».', 'I-PER'), ('Об', 'O'), ('этом', 'O'), ('«', 'O'), ('Спорт', 'O'), ('-', 'O'), ('Экспрессу', 'O'), ('»', 'O'), ('сообщил', 'O'), ('генеральный', 'O'), ('директор', 'O'), ('клуба', 'O'), ('Равиль', 'B-PER'), ('Измайлов', 'I-PER'), ('.', 'O')]\n",
            "BIGRU\n",
            "[('Бывший', 'O'), ('нападающий', 'O'), ('«', 'O'), ('Динамо', 'B-ORG'), ('»', 'O'), ('Сильвестр', 'B-PER'), ('Игбун', 'I-PER'), ('подписал', 'O'), ('контракт', 'O'), ('с', 'O'), ('«', 'O'), ('Нижним', 'B-PER'), ('Новгородом', 'I-PER'), ('».', 'I-PER'), ('Об', 'O'), ('этом', 'O'), ('«', 'O'), ('Спорт', 'B-ORG'), ('-', 'O'), ('Экспрессу', 'B-ORG'), ('»', 'O'), ('сообщил', 'O'), ('генеральный', 'O'), ('директор', 'O'), ('клуба', 'O'), ('Равиль', 'B-ORG'), ('Измайлов', 'I-ORG'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обе модели ошибочно определили \"Нижний Новгород\" в I-PER. BIGRU верно выделила \"Спорт-Экспресс\" как организацию, но в отличие от BILSTM ошиблась, посчитав \"Равиля Измайлова\" организацией."
      ],
      "metadata": {
        "id": "t-kgVIAXpeqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare('Виктор Наворски прилетает в Нью-Йорк, но во время полёта в его родной стране Кракожии (вымышленная славяноязычная страна Восточной Европы) произошёл военный переворот и страна прекратила своё существование.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdhnwZsAp2wo",
        "outputId": "bd7d8479-3077-47bf-8c70-bf6ff616f78e"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BILSTM\n",
            "[('Виктор', 'B-PER'), ('Наворски', 'I-PER'), ('прилетает', 'O'), ('в', 'O'), ('Нью', 'B-LOC'), ('-', 'O'), ('Йорк', 'B-LOC'), (',', 'O'), ('но', 'O'), ('во', 'O'), ('время', 'O'), ('полёта', 'O'), ('в', 'O'), ('его', 'O'), ('родной', 'O'), ('стране', 'O'), ('Кракожии', 'O'), ('(', 'O'), ('вымышленная', 'O'), ('славяноязычная', 'O'), ('страна', 'B-LOC'), ('Восточной', 'I-LOC'), ('Европы', 'I-LOC'), (')', 'O'), ('произошёл', 'O'), ('военный', 'I-ORG'), ('переворот', 'I-ORG'), ('и', 'O'), ('страна', 'O'), ('прекратила', 'O'), ('своё', 'O'), ('существование', 'O'), ('.', 'O')]\n",
            "BIGRU\n",
            "[('Виктор', 'B-PER'), ('Наворски', 'I-PER'), ('прилетает', 'O'), ('в', 'O'), ('Нью', 'B-LOC'), ('-', 'O'), ('Йорк', 'B-LOC'), (',', 'O'), ('но', 'O'), ('во', 'O'), ('время', 'O'), ('полёта', 'O'), ('в', 'O'), ('его', 'O'), ('родной', 'O'), ('стране', 'O'), ('Кракожии', 'O'), ('(', 'O'), ('вымышленная', 'B-LOC'), ('славяноязычная', 'I-LOC'), ('страна', 'I-LOC'), ('Восточной', 'I-LOC'), ('Европы', 'I-LOC'), (')', 'O'), ('произошёл', 'B-ORG'), ('военный', 'I-ORG'), ('переворот', 'I-ORG'), ('и', 'O'), ('страна', 'O'), ('прекратила', 'O'), ('своё', 'O'), ('существование', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обе модели причислили много лишнего к именованным сущностям, BILSTM сделала меньше ошибок"
      ],
      "metadata": {
        "id": "3hzUnGsDtEiP"
      }
    }
  ]
}